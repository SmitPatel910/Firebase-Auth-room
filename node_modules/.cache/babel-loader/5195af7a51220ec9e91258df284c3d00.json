{"ast":null,"code":"\"use strict\";\n\nvar _wrapNativeSuper = require(\"C:\\\\Users\\\\Smit\\\\Desktop\\\\RTC-React\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/wrapNativeSuper\");\n\nvar _regeneratorRuntime = require(\"C:\\\\Users\\\\Smit\\\\Desktop\\\\RTC-React\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"C:\\\\Users\\\\Smit\\\\Desktop\\\\RTC-React\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/asyncToGenerator\");\n\nvar _possibleConstructorReturn = require(\"C:\\\\Users\\\\Smit\\\\Desktop\\\\RTC-React\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/possibleConstructorReturn\");\n\nvar _getPrototypeOf = require(\"C:\\\\Users\\\\Smit\\\\Desktop\\\\RTC-React\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/getPrototypeOf\");\n\nvar _inherits = require(\"C:\\\\Users\\\\Smit\\\\Desktop\\\\RTC-React\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/inherits\");\n\nvar _classCallCheck = require(\"C:\\\\Users\\\\Smit\\\\Desktop\\\\RTC-React\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"C:\\\\Users\\\\Smit\\\\Desktop\\\\RTC-React\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/createClass\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar assert = require(\"assert\");\n\nvar backoff_1 = require(\"./backoff\");\n\nvar rate_limiter_1 = require(\"./rate-limiter\");\n\nvar timestamp_1 = require(\"./timestamp\");\n\nvar util_1 = require(\"./util\");\n\nvar write_batch_1 = require(\"./write-batch\");\n\nvar validate_1 = require(\"./validate\");\n\nvar logger_1 = require(\"./logger\");\n/*!\n * The maximum number of writes that can be in a single batch.\n */\n\n\nvar MAX_BATCH_SIZE = 20;\n/*!\n * The maximum number of writes can be can in a single batch that is being retried.\n */\n\nexports.RETRY_MAX_BATCH_SIZE = 10;\n/*!\n * The starting maximum number of operations per second as allowed by the\n * 500/50/5 rule.\n *\n * https://firebase.google.com/docs/firestore/best-practices#ramping_up_traffic.\n */\n\nexports.DEFAULT_INITIAL_OPS_PER_SECOND_LIMIT = 500;\n/*!\n * The maximum number of operations per second as allowed by the 500/50/5 rule.\n * By default the rate limiter will not exceed this value.\n *\n * https://firebase.google.com/docs/firestore/best-practices#ramping_up_traffic.\n */\n\nexports.DEFAULT_MAXIMUM_OPS_PER_SECOND_LIMIT = 10000;\n/*!\n * The default jitter to apply to the exponential backoff used in retries. For\n * example, a factor of 0.3 means a 30% jitter is applied.\n */\n\nexports.DEFAULT_JITTER_FACTOR = 0.3;\n/*!\n * The rate by which to increase the capacity as specified by the 500/50/5 rule.\n */\n\nvar RATE_LIMITER_MULTIPLIER = 1.5;\n/*!\n * How often the operations per second capacity should increase in milliseconds\n * as specified by the 500/50/5 rule.\n */\n\nvar RATE_LIMITER_MULTIPLIER_MILLIS = 5 * 60 * 1000;\n/*!\n * The default maximum number of pending operations that can be enqueued onto a\n * BulkWriter instance. An operation is considered pending if BulkWriter has\n * sent it via RPC and is awaiting the result. BulkWriter buffers additional\n * writes after this many pending operations in order to avoiding going OOM.\n */\n\nvar DEFAULT_MAXIMUM_PENDING_OPERATIONS_COUNT = 500;\n/**\n * Represents a single write for BulkWriter, encapsulating operation dispatch\n * and error handling.\n * @private\n * @internal\n */\n\nvar BulkWriterOperation = /*#__PURE__*/function () {\n  /**\n   * @param ref The document reference being written to.\n   * @param type The type of operation that created this write.\n   * @param sendFn A callback to invoke when the operation should be sent.\n   * @param errorFn The user provided global error callback.\n   * @param successFn The user provided global success callback.\n   */\n  function BulkWriterOperation(ref, type, sendFn, errorFn, successFn) {\n    _classCallCheck(this, BulkWriterOperation);\n\n    this.ref = ref;\n    this.type = type;\n    this.sendFn = sendFn;\n    this.errorFn = errorFn;\n    this.successFn = successFn;\n    this.deferred = new util_1.Deferred();\n    this.failedAttempts = 0;\n    this._backoffDuration = 0;\n    /** Whether flush() was called when this was the last enqueued operation. */\n\n    this._flushed = false;\n  }\n\n  _createClass(BulkWriterOperation, [{\n    key: \"markFlushed\",\n    value: function markFlushed() {\n      this._flushed = true;\n    }\n  }, {\n    key: \"onError\",\n    value: function onError(error) {\n      ++this.failedAttempts;\n\n      try {\n        var bulkWriterError = new BulkWriterError(error.code, error.message, this.ref, this.type, this.failedAttempts);\n        var shouldRetry = this.errorFn(bulkWriterError);\n        logger_1.logger('BulkWriter.errorFn', null, 'Ran error callback on error code:', error.code, ', shouldRetry:', shouldRetry, ' for document:', this.ref.path);\n\n        if (shouldRetry) {\n          this.lastStatus = error.code;\n          this.updateBackoffDuration();\n          this.sendFn(this);\n        } else {\n          this.deferred.reject(bulkWriterError);\n        }\n      } catch (userCallbackError) {\n        this.deferred.reject(userCallbackError);\n      }\n    }\n  }, {\n    key: \"updateBackoffDuration\",\n    value: function updateBackoffDuration() {\n      if (this.lastStatus === 8\n      /* RESOURCE_EXHAUSTED */\n      ) {\n          this._backoffDuration = backoff_1.DEFAULT_BACKOFF_MAX_DELAY_MS;\n        } else if (this._backoffDuration === 0) {\n        this._backoffDuration = backoff_1.DEFAULT_BACKOFF_INITIAL_DELAY_MS;\n      } else {\n        this._backoffDuration *= backoff_1.DEFAULT_BACKOFF_FACTOR;\n      }\n    }\n  }, {\n    key: \"onSuccess\",\n    value: function onSuccess(result) {\n      try {\n        this.successFn(this.ref, result);\n        this.deferred.resolve(result);\n      } catch (userCallbackError) {\n        this.deferred.reject(userCallbackError);\n      }\n    }\n  }, {\n    key: \"promise\",\n    get: function get() {\n      return this.deferred.promise;\n    }\n  }, {\n    key: \"backoffDuration\",\n    get: function get() {\n      return this._backoffDuration;\n    }\n  }, {\n    key: \"flushed\",\n    get: function get() {\n      return this._flushed;\n    }\n  }]);\n\n  return BulkWriterOperation;\n}();\n/**\n * Used to represent a batch on the BatchQueue.\n *\n * @private\n * @internal\n */\n\n\nvar BulkCommitBatch = /*#__PURE__*/function (_write_batch_1$WriteB) {\n  _inherits(BulkCommitBatch, _write_batch_1$WriteB);\n\n  function BulkCommitBatch(firestore, maxBatchSize) {\n    var _this;\n\n    _classCallCheck(this, BulkCommitBatch);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(BulkCommitBatch).call(this, firestore)); // The set of document reference paths present in the WriteBatch.\n\n    _this.docPaths = new Set(); // An array of pending write operations. Only contains writes that have not\n    // been resolved.\n\n    _this.pendingOps = [];\n    _this._maxBatchSize = maxBatchSize;\n    return _this;\n  }\n\n  _createClass(BulkCommitBatch, [{\n    key: \"setMaxBatchSize\",\n    value: function setMaxBatchSize(size) {\n      assert(this.pendingOps.length <= size, 'New batch size cannot be less than the number of enqueued writes');\n      this._maxBatchSize = size;\n    }\n  }, {\n    key: \"has\",\n    value: function has(documentRef) {\n      return this.docPaths.has(documentRef.path);\n    }\n  }, {\n    key: \"bulkCommit\",\n    value: function () {\n      var _bulkCommit = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var options,\n            _a,\n            tag,\n            stack,\n            response,\n            retryCodes,\n            ops,\n            i,\n            DELETE_TIMESTAMP_SENTINEL,\n            status,\n            updateTime,\n            error,\n            _args = arguments;\n\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                options = _args.length > 0 && _args[0] !== undefined ? _args[0] : {};\n                tag = (_a = options === null || options === void 0 ? void 0 : options.requestTag) !== null && _a !== void 0 ? _a : util_1.requestTag(); // Capture the error stack to preserve stack tracing across async calls.\n\n                stack = Error().stack;\n                _context.prev = 3;\n                logger_1.logger('BulkCommitBatch.bulkCommit', tag, \"Sending next batch with \".concat(this._opCount, \" writes\"));\n                retryCodes = util_1.getRetryCodes('batchWrite');\n                _context.next = 8;\n                return this._commit({\n                  retryCodes: retryCodes,\n                  methodName: 'batchWrite',\n                  requestTag: tag\n                });\n\n              case 8:\n                response = _context.sent;\n                _context.next = 15;\n                break;\n\n              case 11:\n                _context.prev = 11;\n                _context.t0 = _context[\"catch\"](3);\n                // Map the failure to each individual write's result.\n                ops = Array.from({\n                  length: this.pendingOps.length\n                });\n                response = {\n                  writeResults: ops.map(function () {\n                    return {};\n                  }),\n                  status: ops.map(function () {\n                    return _context.t0;\n                  })\n                };\n\n              case 15:\n                for (i = 0; i < (response.writeResults || []).length; ++i) {\n                  // Since delete operations currently do not have write times, use a\n                  // sentinel Timestamp value.\n                  // TODO(b/158502664): Use actual delete timestamp.\n                  DELETE_TIMESTAMP_SENTINEL = timestamp_1.Timestamp.fromMillis(0);\n                  status = (response.status || [])[i];\n\n                  if (status.code === 0\n                  /* OK */\n                  ) {\n                      updateTime = timestamp_1.Timestamp.fromProto(response.writeResults[i].updateTime || DELETE_TIMESTAMP_SENTINEL);\n                      this.pendingOps[i].onSuccess(new write_batch_1.WriteResult(updateTime));\n                    } else {\n                    error = new (require('google-gax').GoogleError)(status.message || undefined);\n                    error.code = status.code;\n                    this.pendingOps[i].onError(util_1.wrapError(error, stack));\n                  }\n                }\n\n              case 16:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this, [[3, 11]]);\n      }));\n\n      function bulkCommit() {\n        return _bulkCommit.apply(this, arguments);\n      }\n\n      return bulkCommit;\n    }()\n    /**\n     * Helper to update data structures associated with the operation and returns\n     * the result.\n     */\n\n  }, {\n    key: \"processLastOperation\",\n    value: function processLastOperation(op) {\n      assert(!this.docPaths.has(op.ref.path), 'Batch should not contain writes to the same document');\n      this.docPaths.add(op.ref.path);\n      this.pendingOps.push(op);\n    }\n  }, {\n    key: \"maxBatchSize\",\n    get: function get() {\n      return this._maxBatchSize;\n    }\n  }]);\n\n  return BulkCommitBatch;\n}(write_batch_1.WriteBatch);\n/**\n * Used to represent a buffered BulkWriterOperation.\n *\n * @private\n * @internal\n */\n\n\nvar BufferedOperation = function BufferedOperation(operation, sendFn) {\n  _classCallCheck(this, BufferedOperation);\n\n  this.operation = operation;\n  this.sendFn = sendFn;\n};\n/**\n * The error thrown when a BulkWriter operation fails.\n *\n * @class BulkWriterError\n */\n\n\nvar BulkWriterError = /*#__PURE__*/function (_Error) {\n  _inherits(BulkWriterError, _Error);\n\n  /** @hideconstructor */\n  function BulkWriterError(\n  /** The status code of the error. */\n  code,\n  /** The error message of the error. */\n  message,\n  /** The document reference the operation was performed on. */\n  documentRef,\n  /** The type of operation performed. */\n  operationType,\n  /** How many times this operation has been attempted unsuccessfully. */\n  failedAttempts) {\n    var _this2;\n\n    _classCallCheck(this, BulkWriterError);\n\n    _this2 = _possibleConstructorReturn(this, _getPrototypeOf(BulkWriterError).call(this, message));\n    _this2.code = code;\n    _this2.message = message;\n    _this2.documentRef = documentRef;\n    _this2.operationType = operationType;\n    _this2.failedAttempts = failedAttempts;\n    return _this2;\n  }\n\n  return BulkWriterError;\n}(_wrapNativeSuper(Error));\n\nexports.BulkWriterError = BulkWriterError;\n/**\n * A Firestore BulkWriter that can be used to perform a large number of writes\n * in parallel.\n *\n * @class BulkWriter\n */\n\nvar BulkWriter = /*#__PURE__*/function () {\n  /** @hideconstructor */\n  function BulkWriter(firestore, options) {\n    _classCallCheck(this, BulkWriter);\n\n    var _a, _b;\n\n    this.firestore = firestore;\n    /**\n     * The maximum number of writes that can be in a single batch.\n     * Visible for testing.\n     * @private\n     * @internal\n     */\n\n    this._maxBatchSize = MAX_BATCH_SIZE;\n    /**\n     * The batch that is currently used to schedule operations. Once this batch\n     * reaches maximum capacity, a new batch is created.\n     * @private\n     * @internal\n     */\n\n    this._bulkCommitBatch = new BulkCommitBatch(this.firestore, this._maxBatchSize);\n    /**\n     * A pointer to the tail of all active BulkWriter operations. This pointer\n     * is advanced every time a new write is enqueued.\n     * @private\n     * @internal\n     */\n\n    this._lastOp = Promise.resolve();\n    /**\n     * Whether this BulkWriter instance has started to close. Afterwards, no\n     * new operations can be enqueued, except for retry operations scheduled by\n     * the error handler.\n     * @private\n     * @internal\n     */\n\n    this._closing = false;\n    /**\n     * The number of pending operations enqueued on this BulkWriter instance.\n     * An operation is considered pending if BulkWriter has sent it via RPC and\n     * is awaiting the result.\n     * @private\n     * @internal\n     */\n\n    this._pendingOpsCount = 0;\n    /**\n     * An array containing buffered BulkWriter operations after the maximum number\n     * of pending operations has been enqueued.\n     * @private\n     * @internal\n     */\n\n    this._bufferedOperations = [];\n    /**\n     * Whether a custom error handler has been set. BulkWriter only swallows\n     * errors if an error handler is set. Otherwise, an UnhandledPromiseRejection\n     * is thrown by Node if an operation promise is rejected without being\n     * handled.\n     * @private\n     * @internal\n     */\n\n    this._errorHandlerSet = false;\n    /**\n     * The maximum number of pending operations that can be enqueued onto this\n     * BulkWriter instance. Once the this number of writes have been enqueued,\n     * subsequent writes are buffered.\n     * @private\n     * @internal\n     */\n\n    this._maxPendingOpCount = DEFAULT_MAXIMUM_PENDING_OPERATIONS_COUNT;\n    /**\n     * The user-provided callback to be run every time a BulkWriter operation\n     * successfully completes.\n     * @private\n     * @internal\n     */\n\n    this._successFn = function () {};\n    /**\n     * The user-provided callback to be run every time a BulkWriter operation\n     * fails.\n     * @private\n     * @internal\n     */\n\n\n    this._errorFn = function (error) {\n      var isRetryableDeleteError = error.operationType === 'delete' && error.code === 13\n      /* INTERNAL */\n      ;\n      var retryCodes = util_1.getRetryCodes('batchWrite');\n      return (retryCodes.includes(error.code) || isRetryableDeleteError) && error.failedAttempts < backoff_1.MAX_RETRY_ATTEMPTS;\n    };\n\n    this.firestore._incrementBulkWritersCount();\n\n    validateBulkWriterOptions(options);\n\n    if ((options === null || options === void 0 ? void 0 : options.throttling) === false) {\n      this._rateLimiter = new rate_limiter_1.RateLimiter(Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY);\n    } else {\n      var startingRate = exports.DEFAULT_INITIAL_OPS_PER_SECOND_LIMIT;\n      var maxRate = exports.DEFAULT_MAXIMUM_OPS_PER_SECOND_LIMIT;\n\n      if (typeof (options === null || options === void 0 ? void 0 : options.throttling) !== 'boolean') {\n        if (((_a = options === null || options === void 0 ? void 0 : options.throttling) === null || _a === void 0 ? void 0 : _a.maxOpsPerSecond) !== undefined) {\n          maxRate = options.throttling.maxOpsPerSecond;\n        }\n\n        if (((_b = options === null || options === void 0 ? void 0 : options.throttling) === null || _b === void 0 ? void 0 : _b.initialOpsPerSecond) !== undefined) {\n          startingRate = options.throttling.initialOpsPerSecond;\n        } // The initial validation step ensures that the maxOpsPerSecond is\n        // greater than initialOpsPerSecond. If this inequality is true, that\n        // means initialOpsPerSecond was not set and maxOpsPerSecond is less\n        // than the default starting rate.\n\n\n        if (maxRate < startingRate) {\n          startingRate = maxRate;\n        } // Ensure that the batch size is not larger than the number of allowed\n        // operations per second.\n\n\n        if (startingRate < this._maxBatchSize) {\n          this._maxBatchSize = startingRate;\n        }\n      }\n\n      this._rateLimiter = new rate_limiter_1.RateLimiter(startingRate, RATE_LIMITER_MULTIPLIER, RATE_LIMITER_MULTIPLIER_MILLIS, maxRate);\n    }\n  } // Visible for testing.\n\n\n  _createClass(BulkWriter, [{\n    key: \"_getBufferedOperationsCount\",\n    value: function _getBufferedOperationsCount() {\n      return this._bufferedOperations.length;\n    } // Visible for testing.\n\n  }, {\n    key: \"_setMaxBatchSize\",\n    value: function _setMaxBatchSize(size) {\n      assert(this._bulkCommitBatch.pendingOps.length === 0, 'BulkCommitBatch should be empty');\n      this._maxBatchSize = size;\n      this._bulkCommitBatch = new BulkCommitBatch(this.firestore, size);\n    } // Visible for testing.\n\n  }, {\n    key: \"_setMaxPendingOpCount\",\n    value: function _setMaxPendingOpCount(newMax) {\n      this._maxPendingOpCount = newMax;\n    }\n    /**\n     * Create a document with the provided data. This single operation will fail\n     * if a document exists at its location.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * created.\n     * @param {T} data The object to serialize as the document.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.collection('col').doc();\n     *\n     * bulkWriter\n     *  .create(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"create\",\n    value: function create(documentRef, data) {\n      this._verifyNotClosed();\n\n      return this._enqueue(documentRef, 'create', function (bulkCommitBatch) {\n        return bulkCommitBatch.create(documentRef, data);\n      });\n    }\n    /**\n     * Delete a document from the database.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * deleted.\n     * @param {Precondition=} precondition A precondition to enforce for this\n     * delete.\n     * @param {Timestamp=} precondition.lastUpdateTime If set, enforces that the\n     * document was last updated at lastUpdateTime. Fails the batch if the\n     * document doesn't exist or was last updated at a different time.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the delete. If the delete fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.doc('col/doc');\n     *\n     * bulkWriter\n     *  .delete(documentRef)\n     *  .then(result => {\n     *    console.log('Successfully deleted document');\n     *  })\n     *  .catch(err => {\n     *    console.log('Delete failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"delete\",\n    value: function _delete(documentRef, precondition) {\n      this._verifyNotClosed();\n\n      return this._enqueue(documentRef, 'delete', function (bulkCommitBatch) {\n        return bulkCommitBatch.delete(documentRef, precondition);\n      });\n    }\n    /**\n     * Write to the document referred to by the provided\n     * [DocumentReference]{@link DocumentReference}. If the document does not\n     * exist yet, it will be created. If you pass [SetOptions]{@link SetOptions}.,\n     * the provided data can be merged into the existing document.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * set.\n     * @param {T} data The object to serialize as the document.\n     * @param {SetOptions=} options An object to configure the set behavior.\n     * @param {boolean=} options.merge - If true, set() merges the values\n     * specified in its data argument. Fields omitted from this set() call remain\n     * untouched.\n     * @param {Array.<string|FieldPath>=} options.mergeFields - If provided, set()\n     * only replaces the specified field paths. Any field path that is not\n     * specified is ignored and remains untouched.\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.collection('col').doc();\n     *\n     * bulkWriter\n     *  .set(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"set\",\n    value: function set(documentRef, data, options) {\n      this._verifyNotClosed();\n\n      return this._enqueue(documentRef, 'set', function (bulkCommitBatch) {\n        return bulkCommitBatch.set(documentRef, data, options);\n      });\n    }\n    /**\n     * Update fields of the document referred to by the provided\n     * [DocumentReference]{@link DocumentReference}. If the document doesn't yet\n     * exist, the update fails and the entire batch will be rejected.\n     *\n     * The update() method accepts either an object with field paths encoded as\n     * keys and field values encoded as values, or a variable number of arguments\n     * that alternate between field paths and field values. Nested fields can be\n     * updated by providing dot-separated field path strings or by providing\n     * FieldPath objects.\n     *\n     *\n     * A Precondition restricting this update can be specified as the last\n     * argument.\n     *\n     * @param {DocumentReference} documentRef A reference to the document to be\n     * updated.\n     * @param {UpdateData|string|FieldPath} dataOrField An object containing the\n     * fields and values with which to update the document or the path of the\n     * first field to update.\n     * @param {...(Precondition|*|string|FieldPath)} preconditionOrValues - An\n     * alternating list of field paths and values to update or a Precondition to\n     * restrict this update\n     * @returns {Promise<WriteResult>} A promise that resolves with the result of\n     * the write. If the write fails, the promise is rejected with a\n     * [BulkWriterError]{@link BulkWriterError}.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     * let documentRef = firestore.doc('col/doc');\n     *\n     * bulkWriter\n     *  .update(documentRef, {foo: 'bar'})\n     *  .then(result => {\n     *    console.log('Successfully executed write at: ', result);\n     *  })\n     *  .catch(err => {\n     *    console.log('Write failed with: ', err);\n     *  });\n     * });\n     */\n\n  }, {\n    key: \"update\",\n    value: function update(documentRef, dataOrField) {\n      for (var _len = arguments.length, preconditionOrValues = new Array(_len > 2 ? _len - 2 : 0), _key = 2; _key < _len; _key++) {\n        preconditionOrValues[_key - 2] = arguments[_key];\n      }\n\n      this._verifyNotClosed();\n\n      return this._enqueue(documentRef, 'update', function (bulkCommitBatch) {\n        return bulkCommitBatch.update.apply(bulkCommitBatch, [documentRef, dataOrField].concat(preconditionOrValues));\n      });\n    }\n    /**\n     * Callback function set by {@link BulkWriter#onWriteResult} that is run\n     * every time a {@link BulkWriter} operation successfully completes.\n     *\n     * @callback BulkWriter~successCallback\n     * @param {DocumentReference} documentRef The document reference the\n     * operation was performed on\n     * @param {WriteResult} result The server write time of the operation.\n     */\n\n    /**\n     * Attaches a listener that is run every time a BulkWriter operation\n     * successfully completes.\n     *\n     * @param {BulkWriter~successCallback} successCallback A callback to be\n     * called every time a BulkWriter operation successfully completes.\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter\n     *   .onWriteResult((documentRef, result) => {\n     *     console.log(\n     *       'Successfully executed write on document: ',\n     *       documentRef,\n     *       ' at: ',\n     *       result\n     *     );\n     *   });\n     */\n\n  }, {\n    key: \"onWriteResult\",\n    value: function onWriteResult(successCallback) {\n      this._successFn = successCallback;\n    }\n    /**\n     * Callback function set by {@link BulkWriter#onWriteError} that is run when\n     * a write fails in order to determine whether {@link BulkWriter} should\n     * retry the operation.\n     *\n     * @callback BulkWriter~shouldRetryCallback\n     * @param {BulkWriterError} error The error object with information about the\n     * operation and error.\n     * @returns {boolean} Whether or not to retry the failed operation. Returning\n     * `true` retries the operation. Returning `false` will stop the retry loop.\n     */\n\n    /**\n     * Attaches an error handler listener that is run every time a BulkWriter\n     * operation fails.\n     *\n     * BulkWriter has a default error handler that retries UNAVAILABLE and\n     * ABORTED errors up to a maximum of 10 failed attempts. When an error\n     * handler is specified, the default error handler will be overwritten.\n     *\n     * @param shouldRetryCallback {BulkWriter~shouldRetryCallback} A callback to\n     * be called every time a BulkWriter operation fails. Returning `true` will\n     * retry the operation. Returning `false` will stop the retry loop.\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter\n     *   .onWriteError((error) => {\n     *     if (\n     *       error.code === GrpcStatus.UNAVAILABLE &&\n     *       error.failedAttempts < MAX_RETRY_ATTEMPTS\n     *     ) {\n     *       return true;\n     *     } else {\n     *       console.log('Failed write at document: ', error.documentRef);\n     *       return false;\n     *     }\n     *   });\n     */\n\n  }, {\n    key: \"onWriteError\",\n    value: function onWriteError(shouldRetryCallback) {\n      this._errorHandlerSet = true;\n      this._errorFn = shouldRetryCallback;\n    }\n    /**\n     * Commits all writes that have been enqueued up to this point in parallel.\n     *\n     * Returns a Promise that resolves when all currently queued operations have\n     * been committed. The Promise will never be rejected since the results for\n     * each individual operation are conveyed via their individual Promises.\n     *\n     * The Promise resolves immediately if there are no pending writes. Otherwise,\n     * the Promise waits for all previously issued writes, but it does not wait\n     * for writes that were added after the method is called. If you want to wait\n     * for additional writes, call `flush()` again.\n     *\n     * @return {Promise<void>} A promise that resolves when all enqueued writes\n     * up to this point have been committed.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter.create(documentRef, {foo: 'bar'});\n     * bulkWriter.update(documentRef2, {foo: 'bar'});\n     * bulkWriter.delete(documentRef3);\n     * await flush().then(() => {\n     *   console.log('Executed all writes');\n     * });\n     */\n\n  }, {\n    key: \"flush\",\n    value: function flush() {\n      this._verifyNotClosed();\n\n      this._scheduleCurrentBatch(\n      /* flush= */\n      true); // Mark the most recent operation as flushed to ensure that the batch\n      // containing it will be sent once it's popped from the buffer.\n\n\n      if (this._bufferedOperations.length > 0) {\n        this._bufferedOperations[this._bufferedOperations.length - 1].operation.markFlushed();\n      }\n\n      return this._lastOp;\n    }\n    /**\n     * Commits all enqueued writes and marks the BulkWriter instance as closed.\n     *\n     * After calling `close()`, calling any method will throw an error. Any\n     * retries scheduled as part of an `onWriteError()` handler will be run\n     * before the `close()` promise resolves.\n     *\n     * Returns a Promise that resolves when there are no more pending writes. The\n     * Promise will never be rejected. Calling this method will send all requests.\n     * The promise resolves immediately if there are no pending writes.\n     *\n     * @return {Promise<void>} A promise that resolves when all enqueued writes\n     * up to this point have been committed.\n     *\n     * @example\n     * let bulkWriter = firestore.bulkWriter();\n     *\n     * bulkWriter.create(documentRef, {foo: 'bar'});\n     * bulkWriter.update(documentRef2, {foo: 'bar'});\n     * bulkWriter.delete(documentRef3);\n     * await close().then(() => {\n     *   console.log('Executed all writes');\n     * });\n     */\n\n  }, {\n    key: \"close\",\n    value: function close() {\n      this._verifyNotClosed();\n\n      this.firestore._decrementBulkWritersCount();\n\n      var flushPromise = this.flush();\n      this._closing = true;\n      return flushPromise;\n    }\n    /**\n     * Throws an error if the BulkWriter instance has been closed.\n     * @private\n     * @internal\n     */\n\n  }, {\n    key: \"_verifyNotClosed\",\n    value: function _verifyNotClosed() {\n      if (this._closing) {\n        throw new Error('BulkWriter has already been closed.');\n      }\n    }\n    /**\n     * Sends the current batch and resets `this._bulkCommitBatch`.\n     *\n     * @param flush If provided, keeps re-sending operations until no more\n     * operations are enqueued. This allows retries to resolve as part of a\n     * `flush()` or `close()` call.\n     * @private\n     * @internal\n     */\n\n  }, {\n    key: \"_scheduleCurrentBatch\",\n    value: function _scheduleCurrentBatch() {\n      var _this3 = this;\n\n      var flush = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      if (this._bulkCommitBatch._opCount === 0) return;\n      var pendingBatch = this._bulkCommitBatch;\n      this._bulkCommitBatch = new BulkCommitBatch(this.firestore, this._maxBatchSize); // Use the write with the longest backoff duration when determining backoff.\n\n      var highestBackoffDuration = pendingBatch.pendingOps.reduce(function (prev, cur) {\n        return prev.backoffDuration > cur.backoffDuration ? prev : cur;\n      }).backoffDuration;\n\n      var backoffMsWithJitter = BulkWriter._applyJitter(highestBackoffDuration);\n\n      var delayedExecution = new util_1.Deferred();\n\n      if (backoffMsWithJitter > 0) {\n        backoff_1.delayExecution(function () {\n          return delayedExecution.resolve();\n        }, backoffMsWithJitter);\n      } else {\n        delayedExecution.resolve();\n      }\n\n      delayedExecution.promise.then(function () {\n        return _this3._sendBatch(pendingBatch, flush);\n      });\n    }\n    /**\n     * Sends the provided batch once the rate limiter does not require any delay.\n     * @private\n     * @internal\n     */\n\n  }, {\n    key: \"_sendBatch\",\n    value: function () {\n      var _sendBatch2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(batch) {\n        var _this4 = this;\n\n        var flush,\n            tag,\n            underRateLimit,\n            delayMs,\n            _args2 = arguments;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                flush = _args2.length > 1 && _args2[1] !== undefined ? _args2[1] : false;\n                tag = util_1.requestTag(); // Send the batch if it is does not require any delay, or schedule another\n                // attempt after the appropriate timeout.\n\n                underRateLimit = this._rateLimiter.tryMakeRequest(batch._opCount);\n\n                if (!underRateLimit) {\n                  _context2.next = 9;\n                  break;\n                }\n\n                _context2.next = 6;\n                return batch.bulkCommit({\n                  requestTag: tag\n                });\n\n              case 6:\n                if (flush) this._scheduleCurrentBatch(flush);\n                _context2.next = 12;\n                break;\n\n              case 9:\n                delayMs = this._rateLimiter.getNextRequestDelayMs(batch._opCount);\n                logger_1.logger('BulkWriter._sendBatch', tag, \"Backing off for \".concat(delayMs, \" seconds\"));\n                backoff_1.delayExecution(function () {\n                  return _this4._sendBatch(batch, flush);\n                }, delayMs);\n\n              case 12:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function _sendBatch(_x) {\n        return _sendBatch2.apply(this, arguments);\n      }\n\n      return _sendBatch;\n    }()\n    /**\n     * Adds a 30% jitter to the provided backoff.\n     *\n     * @private\n     * @internal\n     */\n\n  }, {\n    key: \"_enqueue\",\n\n    /**\n     * Schedules and runs the provided operation on the next available batch.\n     * @private\n     * @internal\n     */\n    value: function _enqueue(ref, type, enqueueOnBatchCallback) {\n      var _this5 = this;\n\n      var bulkWriterOp = new BulkWriterOperation(ref, type, this._sendFn.bind(this, enqueueOnBatchCallback), this._errorFn.bind(this), this._successFn.bind(this)); // Swallow the error if the developer has set an error listener. This\n      // prevents UnhandledPromiseRejections from being thrown if a floating\n      // BulkWriter operation promise fails when an error handler is specified.\n      //\n      // This is done here in order to chain the caught promise onto `lastOp`,\n      // which ensures that flush() resolves after the operation promise.\n\n      var userPromise = bulkWriterOp.promise.catch(function (err) {\n        if (!_this5._errorHandlerSet) {\n          throw err;\n        } else {\n          return bulkWriterOp.promise;\n        }\n      }); // Advance the `_lastOp` pointer. This ensures that `_lastOp` only resolves\n      // when both the previous and the current write resolve.\n\n      this._lastOp = this._lastOp.then(function () {\n        return util_1.silencePromise(userPromise);\n      }); // Schedule the operation if the BulkWriter has fewer than the maximum\n      // number of allowed pending operations, or add the operation to the\n      // buffer.\n\n      if (this._pendingOpsCount < this._maxPendingOpCount) {\n        this._pendingOpsCount++;\n\n        this._sendFn(enqueueOnBatchCallback, bulkWriterOp);\n      } else {\n        this._bufferedOperations.push(new BufferedOperation(bulkWriterOp, function () {\n          _this5._pendingOpsCount++;\n\n          _this5._sendFn(enqueueOnBatchCallback, bulkWriterOp);\n        }));\n      } // Chain the BulkWriter operation promise with the buffer processing logic\n      // in order to ensure that it runs and that subsequent operations are\n      // enqueued before the next batch is scheduled in `_sendBatch()`.\n\n\n      return userPromise.then(function (res) {\n        _this5._pendingOpsCount--;\n\n        _this5._processBufferedOps();\n\n        return res;\n      }).catch(function (err) {\n        _this5._pendingOpsCount--;\n\n        _this5._processBufferedOps();\n\n        throw err;\n      });\n    }\n    /**\n     * Manages the pending operation counter and schedules the next BulkWriter\n     * operation if we're under the maximum limit.\n     * @private\n     * @internal\n     */\n\n  }, {\n    key: \"_processBufferedOps\",\n    value: function _processBufferedOps() {\n      if (this._pendingOpsCount < this._maxPendingOpCount && this._bufferedOperations.length > 0) {\n        var nextOp = this._bufferedOperations.shift();\n\n        nextOp.sendFn();\n      }\n    }\n    /**\n     * Schedules the provided operations on current BulkCommitBatch.\n     * Sends the BulkCommitBatch if it reaches maximum capacity.\n     *\n     * @private\n     * @internal\n     */\n\n  }, {\n    key: \"_sendFn\",\n    value: function _sendFn(enqueueOnBatchCallback, op) {\n      // A backoff duration greater than 0 implies that this batch is a retry.\n      // Retried writes are sent with a batch size of 10 in order to guarantee\n      // that the batch is under the 10MiB limit.\n      if (op.backoffDuration > 0) {\n        if (this._bulkCommitBatch.pendingOps.length >= exports.RETRY_MAX_BATCH_SIZE) {\n          this._scheduleCurrentBatch(\n          /* flush= */\n          false);\n        }\n\n        this._bulkCommitBatch.setMaxBatchSize(exports.RETRY_MAX_BATCH_SIZE);\n      }\n\n      if (this._bulkCommitBatch.has(op.ref)) {\n        // Create a new batch since the backend doesn't support batches with two\n        // writes to the same document.\n        this._scheduleCurrentBatch();\n      }\n\n      enqueueOnBatchCallback(this._bulkCommitBatch);\n\n      this._bulkCommitBatch.processLastOperation(op);\n\n      if (this._bulkCommitBatch._opCount === this._bulkCommitBatch.maxBatchSize) {\n        this._scheduleCurrentBatch();\n      } else if (op.flushed) {\n        // If flush() was called before this operation was enqueued into a batch,\n        // we still need to schedule it.\n        this._scheduleCurrentBatch(\n        /* flush= */\n        true);\n      }\n    }\n  }], [{\n    key: \"_applyJitter\",\n    value: function _applyJitter(backoffMs) {\n      if (backoffMs === 0) return 0; // Random value in [-0.3, 0.3].\n\n      var jitter = exports.DEFAULT_JITTER_FACTOR * (Math.random() * 2 - 1);\n      return Math.min(backoff_1.DEFAULT_BACKOFF_MAX_DELAY_MS, backoffMs + jitter * backoffMs);\n    }\n  }]);\n\n  return BulkWriter;\n}();\n\nexports.BulkWriter = BulkWriter;\n/**\n * Validates the use of 'value' as BulkWriterOptions.\n *\n * @private\n * @internal\n * @param value The BulkWriterOptions object to validate.\n * @throws if the input is not a valid BulkWriterOptions object.\n */\n\nfunction validateBulkWriterOptions(value) {\n  if (validate_1.validateOptional(value, {\n    optional: true\n  })) {\n    return;\n  }\n\n  var argName = 'options';\n\n  if (!util_1.isObject(value)) {\n    throw new Error(\"\".concat(validate_1.invalidArgumentMessage(argName, 'bulkWriter() options argument'), \" Input is not an object.\"));\n  }\n\n  var options = value;\n\n  if (options.throttling === undefined || typeof options.throttling === 'boolean') {\n    return;\n  }\n\n  if (options.throttling.initialOpsPerSecond !== undefined) {\n    validate_1.validateInteger('initialOpsPerSecond', options.throttling.initialOpsPerSecond, {\n      minValue: 1\n    });\n  }\n\n  if (options.throttling.maxOpsPerSecond !== undefined) {\n    validate_1.validateInteger('maxOpsPerSecond', options.throttling.maxOpsPerSecond, {\n      minValue: 1\n    });\n\n    if (options.throttling.initialOpsPerSecond !== undefined && options.throttling.initialOpsPerSecond > options.throttling.maxOpsPerSecond) {\n      throw new Error(\"\".concat(validate_1.invalidArgumentMessage(argName, 'bulkWriter() options argument'), \" \\\"maxOpsPerSecond\\\" cannot be less than \\\"initialOpsPerSecond\\\".\"));\n    }\n  }\n}","map":null,"metadata":{},"sourceType":"script"}